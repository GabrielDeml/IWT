{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "all_tweets = {}\n",
    "all_tweets[\"tweets\"] = []\n",
    "for i in range(0, 16):\n",
    "\ttmp_tweets = {}\n",
    "\twith open('maybe_bad_tweets_v8_{}.json'.format(str(i))) as f:\n",
    "\t\ttmp_tweets = json.load(f)\n",
    "\tall_tweets[\"tweets\"] += tmp_tweets[\"tweets\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92486"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = all_tweets['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idMap = {}\n",
    "clean_tweets = {}\n",
    "clean_tweets['tweets'] = []\n",
    "counter = 0\n",
    "for tweet in all_tweets:\n",
    "\tclean_tweet = {}\n",
    "\tclean_tweet['id'] = tweet['id']\n",
    "\tclean_tweet['text'] = tweet['text']\n",
    "\tclean_tweet['confidence'] = tweet['confidence']\n",
    "\tcounter += 1\n",
    "\tclean_tweets['tweets'].append(clean_tweet)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets[\"tweets\"] = sorted(clean_tweets[\"tweets\"], key=lambda k: k['confidence'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idMap = {}\n",
    "counter = 0\n",
    "for tweet in clean_tweets[\"tweets\"]:\n",
    "\tcounter += 1\n",
    "\ttry:\n",
    "\t\tif tweet['id'] not in idMap:\n",
    "\t\t\tidMap[tweet['id']] = 1\n",
    "\t\telse:\n",
    "\t\t\t# Remove the tweet\n",
    "\t\t\tclean_tweets[\"tweets\"].remove(tweet)\n",
    "\texcept:\n",
    "\t\tprint(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'dict' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6786/2425451672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_tweets\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\"tweets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'dict' and 'str'"
     ]
    }
   ],
   "source": [
    "print(len(clean_tweets-\"tweets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "clean_tweets_without_duplicates = {}\n",
    "clean_tweets_without_duplicates['tweets'] = []\n",
    "counter = 0\n",
    "for tweet in clean_tweets[\"tweets\"]:\n",
    "\tcounter += 1\n",
    "\tif idMap[tweet['id']] == 1:\n",
    "\t\tclean_tweets_without_duplicates['tweets'].append(tweet)\n",
    "print(len(clean_tweets_without_duplicates['tweets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data\n",
    "with open('clean_tweets_without_duplicates_v8.json', 'w') as f:\n",
    "\tjson.dump(clean_tweets_without_duplicates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = [\"ivory\"]\n",
    "    # \"trophy\", \"skin\"\n",
    "    #             \"fur\",\n",
    "    #             \"dragon\",\n",
    "    #             \"pelt\",\n",
    "    #             \"tusk\",\n",
    "    #             \"ivory\",\n",
    "    #             \"scale\",\n",
    "    #             \"taxidermy\",\n",
    "    #             \"rug\",\n",
    "    #             \"hide\",\n",
    "    #             \"bone\",\n",
    "    #             \"meat\",\n",
    "    #             \"delicacy\",\n",
    "    #             \"medicine\",\n",
    "    #             \"live\",\n",
    "    #             \"pangolin\",\n",
    "    #             \"leopard\",\n",
    "    #             \"rhino\",\n",
    "    #             \"sungazer\",\n",
    "    #             \"lizard\",\n",
    "    #             \"crocodile\",\n",
    "    #             \"alligator\",\n",
    "    #             \"parrot\",\n",
    "    #             \"snake\",\n",
    "    #             \"python\",\n",
    "    #             \"yellow material\",\n",
    "    #             \"white plastic\",\n",
    "    #             \"jelly\",\n",
    "    #             \"aloo\",\n",
    "    #             \"kola\",\n",
    "    #             \"australian teddy bear\",\n",
    "    #             \"stripped t-shirt\",\n",
    "    #             \"four wheeler\",\n",
    "    #             \"antique\",\n",
    "    #             \"mammoth\",\n",
    "    #             \"carved\",\n",
    "    #             \"sale\",\n",
    "    #             \"selling\",\n",
    "    #             \"price\",\n",
    "    #             \"xiangya\",\n",
    "    #             \"african material\",\n",
    "    #             \"ANTEBELLUMELEG1\"]\n",
    "suspicious_tweets_word_list = []\n",
    "tweets_with_search_words = []\n",
    "suspicious_tweets_word_count = {}\n",
    "suspicious_tweet_count = 0\n",
    "total_tweets_count = 0\n",
    "followers = 0\n",
    "for word in search_words:\n",
    "    suspicious_tweets_word_count[word] = 0\n",
    "\n",
    "\n",
    "for tweet in clean_tweets_without_duplicates[\"tweets\"]:\n",
    "    # print(tweet)\n",
    "    try:\n",
    "        tweet_text = tweet['text']\n",
    "        tweet_id = tweet['id']\n",
    "        tweet_suspicious = False\n",
    "        bad_tweet = {}\n",
    "        total_tweets_count += 1\n",
    "        for search_word in search_words:\n",
    "            if search_word in tweet_text.lower():\n",
    "                # print(tweet_text)\n",
    "\n",
    "                \n",
    "                # bad_tweet['user'] = tweet['user']\n",
    "                bad_tweet['tweet'] = tweet_text\n",
    "                bad_tweet['id'] = tweet_id\n",
    "                bad_tweet['confidence'] = tweet['confidence']\n",
    "                \n",
    "                if tweet_suspicious == False:\n",
    "                    bad_tweet['suspicious_word'] = [search_word]\n",
    "                    suspicious_tweets_word_list.append([search_word])\n",
    "                    suspicious_tweet_count += 1\n",
    "                else:\n",
    "                    suspicious_tweets_word_list[-1].append(search_word)\n",
    "                    bad_tweet['suspicious_word'].append(search_word)\n",
    "                tweet_suspicious = True\n",
    "                suspicious_tweets_word_count[search_word] += 1\n",
    "        # If bad tweet is not empty\n",
    "        if len(bad_tweet) > 0:\n",
    "            tweets_with_search_words.append(bad_tweet)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data\n",
    "output = {}\n",
    "output['tweets'] = tweets_with_search_words\n",
    "with open('suspicious_tweets_word_count_v8.json', 'w') as f:\n",
    "\tjson.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious tweet count:  14\n",
      "Total tweets:  683\n",
      "Percentage of suspicious tweets:  2.049780380673499\n"
     ]
    }
   ],
   "source": [
    "print(\"Suspicious tweet count: \", suspicious_tweet_count)\n",
    "# print(\"Total followers: \", followers)\n",
    "print(\"Total tweets: \", total_tweets_count)\n",
    "# print(\"Average tweets per follower: \", total_tweets_count/followers)\n",
    "print(\"Percentage of suspicious tweets: \", (suspicious_tweet_count/total_tweets_count)*100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
